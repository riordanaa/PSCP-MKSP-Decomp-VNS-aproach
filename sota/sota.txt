Abstract
The partial set covering problem (PSCP) is a significant combinatorial optimization
problem that finds applications in numerous real-world scenarios. The objective of
PSCP is to encompass a minimum number of subsets while ensuring the coverage of
at least n elements. Due to its NP-hard nature, solving large-scale PSCP efficiently
remains a critical issue in computational intelligence. To effectively tackle this chal-
lenge, we delve into a population-based approach that incorporates a modified tabu
search, thereby striking a delicate balance between exploration and exploitation. To
further enhance its efficacy, we employ the multiple path-relinking strategy and the
fix-and-optimize process. Finally, the dynamic resource allocation scheme is utilized
to save computing efforts. Comparative experiments of the proposed algorithm were
conducted against three state-of-the-art competitors, across two distinct categories,
encompassing 150 instances. The results significantly underscore the profound effec-
tiveness of our proposed algorithm, as evidenced by the updating of 67 best-known
solutions. Moreover, we conduct an in-depth analysis of the key components inherent
to the algorithm, shedding light on their respective influences on the whole perfor-
mance.
Keywords Partial set covering· Tabu search· Multiple path-relinking·
Fix-and-optimize· Dynamic resource allocation

1 Introduction
Covering problems are a fundamental class of optimization problems in mathematics
and computer science that involve finding a minimum-cost or minimum-size collection
of sets that completely cover a given universe. In the classical set covering problem
(SCP), we are given a universe set and a collection of subsets of this universe. The goal
is to select a minimum number of subsets such that their union covers the entire uni-
verse. This problem finds applications in various fields, including logistics Boschetti
and Maniezzo (2015); Alfieri et al. (2007), scheduling Kritter et al. (2019); Yaghini
et al. (2015), network design Liao and Ting (2017); Benhaya et al. (2021), etc. SCP also
demonstrates its value in resource optimization, showcasing its capability to support
comprehensive coverage and optimal configuration under constrained conditions.
Several exact algorithms have been developed to solve the Set Covering Problem
(SCP), such as those proposed by Balas and Carrera (1996) and Beasley and Jörnsten
(1992), which can guarantee optimal solutions given sufficient runtime. However, these
approaches tend to be inefficient, particularly when dealing with large solution spaces.
To address this, approximation algorithms have been introduced Hochbaum (1982);
Bansal et al. (2010). Unfortunately, in practical applications, these algorithms often
fail to deliver satisfactory results in terms of solution quality. As a result, significant
research has focused on heuristic approaches, including genetic algorithm Beasley and
Chu (1996), simulated annealing Brusco et al. (1999), artificial bee colony Crawford
et al. (2014), local search Gao et al. (2014), Gao et al. (2015), Luo et al. (2022), etc.
These efforts highlight the considerable attention SCP has garnered and the extensive
research conducted in this area.
As the era of big data continues to advance, the massive volume of data is expanding
at an unprecedented rate, presenting a more formidable challenge in finding optimal
solutions within the constraints of limited computing resources and time. In response to
this, the partial set covering problem, a modified version of the well-known minimum
set covering problem, has emerged as a viable solution Daskin and Owen (1999); Liu
et al. (2022). The partial set covering problem aims to find a minimum-size collection
of subsets that covers at least a certain percentage, or fraction, of the universe. This
variant takes into account scenarios where covering the entire universe is not necessary,
but rather partial coverage is sufficient.
To provide a concrete illustration of the PSCP, Fig. 1 shows an example within the
context of social networks. The PSCP can be applied to model the spread of informa-
tion or influence among individuals Kempe et al. (2003). Consider a social network
123
An effective population-based… Page 3 of 32 17
Fig. 1 A scenario of PSCP within social networks
where each individual is represented as a node, and the connections between individ-
uals are represented as edges. This network can be referred to as a social graph. To
formulate this problem as a PSCP instance, we can transform the social graph into a
0-1 matrix, in which each subset represents a group of individuals that can propagate
the information to others within the group. Information spreading can be viewed as the
process of selecting a subset of individuals to initially receive the information, with the
aim of maximizing its overall reach within the network. By solving the PSCP, we can
determine the minimum number of individuals needed to reach a certain percentage of
the total population. This allows us to optimize the selection process and identify the
most influential individuals who can efficiently propagate the information throughout
the network, while minimizing the overall dissemination effort. By studying such par-
tial set covering models, we can gain insights into effective strategies for information
dissemination, viral marketing, and other related phenomena in social networks.
The partial set covering problem poses a formidable optimization challenge, estab-
lished as NP-hard Hartmanis (1982). This implies that unless P equals NP, the quest for
a polynomial-time algorithm to solve PSCP optimally remains elusive. Consequently,
researchers have directed their efforts towards crafting approximation algorithms that
yield solutions close to the optimal. Although there are numerous solution methodolo-
gies available for the classical Set Covering Problem Beasley and Chu (1996); Caprara
et al. (2000); Leutwiler and Corman (2023); Emerick et al. (2023), it is important to
note that the literature specifically addressing the algorithmic aspects of the PSCP is
relatively limited. Inamdar et al. Inamdar and Varadarajan (2018) innovatively trans-
formed the Partial Set Covering Problem (PSCP) into SCP using natural LP relaxation
inspired by geometric set systems, setting the stage for further advancements with
their elegantly simple approach. Building upon the foundations laid by Inamdar et al.,
Chekuri et al. Chekuri et al. (2019) enhanced the approximation ratio of PSCP to the
remarkable value of (1−1/e)(β +1), employing a framework akin to that of Inamdar
and Varadarajan (2018). Here, β is the integrality gap of the linear programming for-
mulation of set covering problems. Afterwards, Ran et al. Ran et al. (2021) designed
a parallel algorithm for PSCP which yielded a solution with an approximation ratio
of at most h/(1− 2ε), where h is the maximum number of sets containing the same
elements, and 0 < ε < 0.5 is a constant.
123
17 Page 4 of 32 Y. Zhang et al.
It is important to note that PSCP shares a structural resemblance with the classical set
covering problem, and there exists substantial evidence highlighting the limitations of
approximation algorithms for SCP, as detailed in references Luo et al. (2022) and Wang
et al. (2021). In the same way, approximation algorithms may not always meet the
solution quality requirements of practical applications. Additionally, as the size of the
dataset grows, exact algorithms may require extensive computational efforts, rendering
them impractical for real-world scenarios. Consequently, heuristic algorithms have
emerged as a promising alternative. These algorithms offer a more practical approach to
addressing the PSCP by providing efficient and effective solutions, especially for large-
scale problems. While a profusion of heuristic methods has been proposed for tackling
diverse set covering variants Chaurasia and Kim (2019); Zhou et al. (2023, 2022),
to the best of our knowledge, only two heuristic algorithms have been specifically
designed to tackle the challenges posed by the PSCP. One algorithm is the iterated tabu
search, featuring a dual-level perturbation technique alongside tabu heuristics Bilal
et al. (2014). The other is the Argentine Ant System, leveraging varied populations
within a local search framework, characterized by flexible configuration verification
and a volatilization-fixed weight mechanism Liu et al. (2022). Experimental results
suggest that there is room for improvement in both algorithms. This gap presents an
opportunity for future research work, where scholars can begin to explore and design
more effective heuristic methods to offer high-quality solutions for PSCP instances
encountered in real-world settings.
This paper presents a population-based heuristic framework, namely PSSC, to
address the partial set covering problem. PSSC achieves a balance between exploration
and exploitation. During the exploitation phase, a modified tabu search (MTS) serves as
the foundation for conducting searches with varying intensities. To tackle the issue of
local optima, a fix-and-optimize technique is applied to fix specific elements, followed
by a greedy repair of the incomplete solution. Regarding population interactions, a
multiple path-relinking method facilitates the sharing of knowledge among individu-
als, guiding some solutions towards different directions. Finally, a dynamic resource
allocation strategy is employed to distribute computational resources to promising
solutions, thereby enhancing overall efficiency. The performance of PSSC is assessed
through comprehensive experiments on 150 well-known instances, including 75 previ-
ous ones and 75 new difficult ones. Comparisons with the commercial solver CPLEX,
the state-of-the-art local search RWLS, and the population-based method AAS demon-
strate the effectiveness of PSSC.
The subsequent sections of this manuscript are structured as follows. Section 2 pro-
vides an exposition of the foundational concepts and background knowledge pertinent
to this study. In Sect. 3, we present the proposed framework and key components of
it. The computational results are reported and analyzed in Sect. 4. Finally, in Sect. 5,
we draw the conclusions and summarize the key contributions of this paper.
2 Preliminaries
In this section, we formally introduce the key definitions and notations used throughout
the paper.
123
An effective population-based… Page 5 of 32 17
Set covering problem (SCP) is a well-known NP-hard combinatorial optimization
problem, which aims to find a minimum-size collection of subsets that covers the entire
universe. The SCP is formulated as follows:
s.t.
m
i=1
min
m
i=1
ai j xi ≥ 1, ∀e j ∈ U xi ∈ {0,1}, ∀si ∈ M xi (1)
(2)
(3)
where U = {e1,...,e j,...,eu } is the universe, a finite set of elements. M=
{s1,...,si ,...,sm } is the set of subsets of U , also known as the covering set. ai j= 1 if
subset si covers element e j , and ai j= 0 otherwise. xi is a binary variable indicating
whether subset si is selected or not.
Partial set covering problem (PSCP) is a variant of the SCP that aims to find
the smallest possible collection of subsets that together cover at least a specified
percentage, or fraction, of the universe. PSCP can be formulated as follows:
s.t.
si ∈C j
min
m
i=1
xi (4)
xi ≥ z j, ∀e j ∈ U (5)
z j ≥ n (6)
e j ∈U
z j ∈ {0,1}, ∀e j ∈ U xi ∈ {0,1}, ∀si ∈ M (7)
(8)
where n is the number of desired coverage elements, usually given as a certain per-
centage of U , C j is the set collection that covers element e j . The main distinction
between SCP and PSCP lies in their coverage requirements. The SCP mandates that
all elements within the universe must be covered, whereas the PSCP only demands
that a specified percentage of elements be covered. This makes the PSCP more appli-
cable to various real-world scenarios. It’s worth noting that if n equals |U |, the PSCP
transforms into the SCP.
Maximum set k-covering problem (MSKCP) is a generalization of the set cover-
ing problem that aims to find a collection of k subsets that maximizes the number of
covered elements in the universe. The MSKCP can be formulated as follows:
max
e j ∈U
m
i=1
ai j xi (9)
123
17 Page 6 of 32 Y. Zhang et al.
s.t.
m
i=1
xi = k (10)
xi ∈ {0,1} ∀si ∈ M (11)
where k is the number of selected subsets. The constraint (10) ensures that exactly
k subsets are selected. We introduce MSKCP for the reason that PSCP is effectively
solved by iteratively solving the MSKCP. Starting with a large value of k, the MSKCP
is solved to find the subset that maximizes the coverage. If the coverage requirement
of PSCP is met, the value of k is decremented, and the corresponding MSKCP is
solved again. This process continues until the cut-off condition is met. To the best of
our knowledge, this research represents the first attempt to convert the task of solving
PSCP into a series of stages of solving the MSKCP.
After giving the definitions, we further introduce the reduction rules for solving the
set covering problem. Within SCP, two critical concepts are pivotal: column domina-
tion and column inclusion. Column domination occurs when a column (subset) can
be removed from the solution without impacting coverage, while column inclusion
indicates that a column (subset) is essential for covering a specific element. It is evi-
dent that the initial rule determines certain subsets that are not required to be included,
whereas the latter rule determines subsets that must be included. The details are as
follows:
Column domination rule: If the set of rows covered by a column j is also covered
by another column j ′ with a lower cost, then we say that j is dominated by j ′
.
Dominated columns can be removed from M.
Column inclusion rule: If a specific row is covered by only one unique column,
then this indispensable column is included in every solution.
These rules are particularly useful for solving the SCP, especially in large-scale
instances. In the case of the PSCP, only the first rule remains applicable since not
all columns are necessarily required to be covered. Consequently, the proposed algo-
rithm utilizes the column domination rule to reduce the size of PSCP instances before
commencing the search procedure.
As the proposed algorithm heavily relies on the score value of subset s to guide the
search, we provide the calculation of scor e(s) as follows:
scor e(s)=
f (S) ∪ {s} − f (S), s / ∈ S
f (S) \ {s} − f (S), s ∈ S (12)
where f (S) represents the objective function evaluating the solution S in PSCP.
Now, we give an example of PSCP in Fig. 2 to make the problem comprehensible.
Given a 0–1 matrix of PSCP, the columns c1,c2,c3 and c4 represent subsets of the set
system (U , M), and the rows e1,e2,e3,e4,e5,e6,e7,e8,e9 and e10 represent elements
in U respectively. The term ai j with a mean value of 1 in the matrix means that row i
is covered by column j , that is, the subset c j covers element ei . Suppose that n = 9,
the objective of PSCP is to select the minimum number of subsets such that at least
9 elements are covered. Initially, when the candidate solution S is empty, we select
123
An effective population-based… Page 7 of 32 17
Fig. 2 An example of PSCP with 4 subsets and 10 elements
subset c4 to be included in the candidate solution set, and update the score values of
the remaining subsets accordingly. Consequently, subset c3 is added to the candidate
solution set since it possesses the highest score value of 3. Following this, the constraint
of the PSCP is satisfied, and the optimal solution is S = {c3,c4}. It is important to note
that this is a simple example that can be calculated manually. However, when dealing
with real instances, efficient algorithms are required to solve the problem effectively.
3 The proposed algorithm for PSCP
In this section, we present the effective population-based algorithm, denoted as PSSC,
for solving PSCP. The overall framework is provided, followed by a detailed descrip-
tion of its key components for a comprehensive understanding of this method.
3.1 The general framework
Population-based search is a set of optimization algorithms that utilize the power of
swarm intelligence or evolutionary principles to solve a wide range of optimization
problems Wang and Singh (2008); Prügel-Bennett (2010); Babalola et al. (2020). This
approach searches for new candidate solutions through iterative interactions between
individuals. In this paper, we present a population-based approach to minimize the
selected sets that can cover no less than n elements in PSCP. Within the overall frame-
work, the PSSC algorithm includes steps such as initialization, modified tabu search,
multiple path-relinking, fix-and-optimize strategy, and dynamic resource allocation.
The details of the PSSC algorithm are described in Algorithm 1. First, the relevant
parameters are initialized (lines 1–2). Then, the candidate solution S is constructed
by continuously selecting subsets with the highest score value from the unselected set
pool until the number of covered elements is not less than n (lines 3–5). The objective
function value f (S) becomes the upper bound of PSCP, and the aim of PSSC is to seek
f (S)−1 subsets constantly to meet the constraint in Eq. (6) until the stopping criterion
is met. Then, the whole population P is initialized by I ni t that will be introduced in
123
17 Page 8 of 32 Y. Zhang et al.
Algorithm 1: PSSC framework
// Section 3.3
Input: Population size |P|, elements to be covered n, backtrack step γ, search depth θ.
Output: The best solution S∗ found.
1 mode ← 0, cnt ← 0,i ter ← 0, H C ← 0;
2 S ← ∅, Mar k ← ∅;
3 while S is not feasible do
4 s ← argmax
scor e(s);
s∈M\S
5 S ← S ∪ {s};
6 S∗
, P ← I ni t(p, f (S)− 1); 7 while elapsed time < cutoff time do
8 for each Pd ∈ P do
9 if Pd / ∈ Mar k then
10 Pd ← M T S(Pd , M); 11 if Pd. f i t >= S∗
. f i t then
12 cnt ← 0;
13 H Cd ← H Cd + 1;
14 S∗ ← Pd ;
// Section 3.2
15 16 17 if Pd. f i t >= n then
H Cd ← 0;
S∗
, P ← I ni t(n, f (Pd )− 1); 18 19 20 21 22 23 24 cnt ← cnt + 1;
if cnt = 40 then
cnt ← 0;
Pd ← argmax
H Cd ;
Pd ∈P
S ← F O(Pd , f (S∗) ∗ θ,γ); if S. f i t >= S∗.fit then
S∗ ← S;
25 26 27 if S. f i t >= n then
H Ct ← 0;
S∗
, P ← I ni t(n, f (S)− 1); 28 29 30 31 mode, P ← M P R(mode, S∗
if i ter= 5 then
i ter ← 0;
Mar k ← D R A(Mar k, Rmax , H C); 32 i ter ← i ter + 1;
33 return S∗;
// Section 3.2
// Section 3.6
, P, Mar k); // Section 3.2
// Section 3.4
// Section 3.5
Sect. 3.2 (line 6). The algorithm proceeds with a series of iterations (lines 7–32). In
each iteration, M T S is performed on each individual to generate new solutions, and
the population is updated accordingly (lines 8–10). If the fitness value of the obtained
individual Pd surpasses that of the current optimal solution S∗, then S∗ is updated,
and the hit count array is incremented by 1 (lines 11–14). If an individual satisfies
the constraint condition of PSCP, it indicates that a candidate solution has been found
with the objective function of f (Pd ) and will seek better solutions with f (Pd )− 1
(lines 15–17). In such cases, the I ni t function is called to reset and proceed to the next
123
An effective population-based… Page 9 of 32 17
cycle of search. Note that we use the objective function of MSKCP in Eq. (9) as the
fitness function and use the objective function of PSCP in Eq. (4) as the final f value.
In every 40 iterations, the fix-and-optimize method is utilized to fix some subsets and
try to explore new improved solutions of the well-performed individual (lines 19–22).
If a better solution is found, then update the best solution S∗ (lines 23–24). Moreover,
if this solution is feasible, continue to search the space with f (S)− 1 (lines 25–27).
If the above condition is not met, the Multiple Path-Relinking strategy is employed
to ensure diversity among individuals in the population (line 28). In light of the
concern regarding increased computational resource consumption by the population,
which can potentially result in inferior search performance within a specified time
period, we propose the dynamic resource allocation strategy. This strategy aims to
allocate computing resources effectively among the individuals, thereby enhancing
overall search capabilities. After the completion of the cycle, the algorithm invokes
the D R A to reassign computing resources based on the performance of each individual
within the population during that cycle (lines 29–32). Once the termination condition
is satisfied, the algorithm returns the best solution obtained during the search process
(line 33).
Algorithm 2: Initialization procedure–I ni t
Input: Desired coverage elements n, upper bound of the selected subsets kmax.
Output: Local best solution S′, initialized Populati o.
1 Populati on = {P0, P1,..., P|P|} ← ∅; t = 0;
2 Pt ← add the set s with maximum scor e(s) with no more than kmax times until at least n elements
are covered;
3 update Populati on;t = t + 1;
4 while t < |P| do
5 t = t + 1;
6 Pt ← randomly add one set s with no more than kmax times until at least n elements are covered;
7 update Populati on;
8 S′ ← argmin
f (Pd );
Pd ∈Populati on
9 return S′
, Populati on;
3.2 Population initialization
In population-based optimization approaches, the initialization process holds signif-
icant importance in determining the quality and diversity of the initial population.
When addressing the PSCP, a suitable population initialization procedure is crucial to
establish a solid foundation for an effective optimization process. The objective of this
procedure is to generate an initial population that possesses favorable characteristics
for solving the PSCP.
Algorithm 2 presents the pseudocode for this population initialization procedure.
First, an empty population is created, and a counter variable t is set to 0 to traverse the
population (line 1). In the greedy mode (line 2), an individual is generated by selecting
the set with the maximum value of the scor e. This process continues no more than kmax
123
17 Page 10 of 32 Y. Zhang et al.
times until the individual becomes feasible, satisfying Eq. (5). Then, the population
is updated and kmax will also be updated with a smaller value if possible (line 3).
To strike a balance between exploration and exploitation, the remaining individuals
are initialized in random mode by selecting a random set with no more than kmax
times until at least n elements are covered (lines 4–7). This random mode generates
|P| − 1 individuals. Once all individuals have been initialized, the best solution S′
is recorded (line 8). Finally, the best solution S′ along with the entire population is
returned for the subsequent stages (line 9). By employing this appropriate population
initialization procedure, the proposed algorithm begins with a diverse and promising
initial population, laying the groundwork for subsequent search and improvement
operations.
3.3 The modified tabu search
The systematic change of neighborhood within a local search algorithm presents a
straightforward yet highly effective metaheuristic for solving combinatorial optimiza-
tion problems Mladenovi´ c and Hansen (1997). Employing a methodology termed
Modified Tabu Search (MTS), this approach systematically ventures through diverse
neighborhoods adjacent to a particular solution in a sequential manner. This process
facilitates the algorithm’s ability to escape local optima, thereby discovering better
solutions. To clarify, we define three distinct neighborhood sets: N1(x)= R S(S, R=
1, T S), N2(x)= R S(S, R= 2, T S) and N3(x)= R S(S, R= 3, T S). By chang-
ing the neighborhood structure, the algorithm can explore the search space efficiently
and balance exploration and exploitation. This flexibility allows the MTS to adapt to
different problem instances and their unique characteristics, rendering it a robust and
flexible optimization framework.
We utilize MTS to improve the quality of individual solutions in the population.
Algorithm 3 describes the detailed process of the modified tabu search for PSCP.
Given the current solution S, the algorithm initializes the local best solution S′ as S,
sets the search intensity R to 1, and initializes the set of feasible solutionsˆ
S to an
empty set (line 1). The algorithm then proceeds with variable neighborhood descent
at different intensities to find the optimal solution S′. To be specific, the algorithm
executes multiple rounds, each of which begins with setting the search intensity to
1 and recording the objective function of S′ which serves as the lower bound of
the solutions obtained through the search. Subsequently, the algorithm performs a
neighborhood search with the search intensity R. It resets the tabu list T S to an empty
set, initializes the iteration counter i ter to 0, and sets the tabu value tabu(s)= −1
for any set s ∈ M′. Additionally, the algorithm sets the counter t to 0, which keeps
track of the number of iterations in which S has not been updated (lines 3–5). The
algorithm continues to iterate unless t is not less than ϵ. At the beginning of each
iteration, it identifies all sets in the tabu state and adds them to the tabu list T S. A set
s is considered in tabu state only if the current iteration number i ter is less than or
equal to tabu(s). In this case, s is not allowed to be removed from or added to the
current solution S. Otherwise, s is in free state and can be removed from or added to S
(line 7). The refined search (RS) procedure is then invoked to perform a neighborhood
123
An effective population-based… Page 11 of 32 17
Algorithm 3: Modified Tabu Search procedure–M T S
Input: Initial solution S, candidate subset pool M′
.
Output: Local best solution S′ of one individual obtained during the search.
ˆ
1 S′ ← S,
S ← ∅, R ← 1;
2 while R <= 3 andˆ
S = ∅ do
3 S ← S′
, T S ← ∅,i ter ← 0, t ← 0;
4 for each s ∈ M′ do
5 tabu(s) ← −1;
6 while t < ϵ do
7 T S ← {s | s ∈ M′ ∧ tabu(s) <= i ter };
ˆ
8 S2,
S ← R S(S, R, T S);
9 if f (S2) < f (S′) then
10 S′ ← S2, t ← 0, R ← 1;
11 12 13 else
t ← t + R;
R ← R + 1;
14 15 for each s ∈ (S ∪ S2) \ (S ∩ S2) do
tabu(s) ← i ter + ζ;
16 S ← S2,i ter ← i ter + R;
17 return S′;
search on S under the current intensity R, obtaining the feasible solution as well as best
solutions (line 8). The solution S2, obtained by the refined search under the current
R, represents the R-neighborhood of S. If the objective function of S2 is better than
S′, then S′ will be updated to S2 and the counter t is reset to 0, R reset to 1 (lines
9–10). Otherwise, the counter t is incremented by R, and R will increase by 1 (lines
11–13). Before the current iteration stops, the algorithm increases the tabu value of all
sets that have been removed from or added to S during this iteration by ζ (a parameter
controlling the degree of tabu). This ensures that these sets will be in the tabu state
for several subsequent iterations (lines 14–15). Afterwards, S is updated to S2, i ter is
increased by R (line 16). After each round of iteration, the algorithm checks if t > ϵ
andˆ
S is empty. If this condition is true, it indicates that the algorithm has not found a
better solution in more than ϵ iterations and should stop. Otherwise, it proceeds to the
next round of iteration. Through the application of MTS, PSSC can effectively tackle
the PSCP by leveraging the exploitation capabilities of this technique.
Now, we further give the details of the procedure R S in Algorithm 4, which serves
as the searching engine of MTS. Given the input solution S, search intensity R, and
ˆ
tabu list T S, the R S algorithm initiates by setting S′ as S,
S as an empty set, and the
operation count r to 1 (line 1). RS is then divided into two phases, that is, the removal
phase and joining phase. In the removal phase, r sets are selected from S and removed
from it. In each iteration, a non-tabu set s ∈ S is eliminated, resulting in a new solution
S \ {s}. This set of new solutions is referred to as S′, which is then updated to the
new solution with the best f value among all S′ (lines 3–4). If S′ represents a feasible
solution,ˆ
S is updated to S′ (lines 5–6). In the joining phase, r sets are chosen from S
and added back to it. In each iteration, a set s ∈ S that is both non-tabu and not part
123
17 Page 12 of 32 Y. Zhang et al.
Algorithm 4: Refinement search–RS
Input: Initial solution S, search intensity R, tabu set T S, candidate subset pool M′
.
Output: Best solution S′ obtained during the search, the accept solutionˆ
S.
ˆ
1 S′ ← S,
S ← ∅,r ← 1;
2 while r <= R do
3 C ← {Sp | Sp ∈ S′ \ {s} ∧ s ∈ M′ ∧ s / ∈ T S}; // Removal phase
4 S′ ← argmax
f (S′);
S′∈C
5 if S′
. f i t >= n then
6ˆ
S ← S′;
7 r ← r + 1;
8 r ← 1,U ← M′ \ S′;
9 while r <= R do
10 11 C ← {Sp | Sp ∈ S′ ∪ {s} ∧ s / ∈ U ∧ s / ∈ T S}; S′ ← argmax
f (S′);
S′∈C
12 13 14 ifˆ
S / ∈ ∅ then
br eak;
if S′
. f i t >= n then
15ˆ
S ← S′;
16 r ← r + 1;
ˆ
17 return S′
,
S;
// Joining phase
of S′ is added, generating a new solution S ∪ {s}. The set of new solutions is denoted
as S′, which is updated to the new solution with the best f value (lines 10–11). Ifˆ
S
is not an empty set (indicating the discovery of a feasible solution), the neighborhood
search is terminated (lines 12–13). If S′ represents a feasible solution,ˆ
S is updated
to S′ (lines 14–15). Finally, the algorithm returns the best solution S′ and the feasible
solutionˆ
S (line 17). Note that MTS aims to maximize the number of covered elements
using a predefined value of k. It assesses the number of covered elements surpasses a
specified threshold, represented by n. If this condition is met, the algorithm iteratively
performs the same processes with a decreased value of k= k− 1. As a result, PSSC
will yield a collection of k subsets, ensuring the coverage of at least n elements while
simultaneously striving to minimize k.
3.4 The multiple path-relinking procedure
Path relinking is a powerful optimization technique employed to enhance the effi-
ciency and effectiveness of solving complex optimization problems Glover (1997). It
operates by combining solutions from different regions of the search space to construct
improved solutions. Initially, the strategy selects both an initial and a target solution.
Following this, it methodically examines the pathways linking these solutions, con-
tinuously honing and modifying the intermediate solutions encountered during this
exploration. By leveraging the information contained in these paths, the path relinking
strategy fosters the exchange of valuable traits and characteristics between solutions,
leading to the discovery of high-quality solutions. This approach has proven partic-
123
An effective population-based… Page 13 of 32 17
ularly valuable in domains where finding optimal solutions is challenging, such as
jobshop scheduling problems Peng et al. (2015), arc routing problems Usberti et al.
(2013), maximum satisfiability problems Festa et al. (2005), graph coloring problems
Lai et al. (2016), capacitated centered clustering problems Muritiba et al. (2022), etc.
Algorithm 5: Multiple path-relinking procedure–M P R
Pd. f i t;
Pd. f i t;
Input: Phase mode, current best solution S∗, local best solutions for each individual P, markers of
population Mar k.
Output: mode, P.
1 Pt ← ∅, Pd ← ∅;
2 switch mode do
3 case 0
4 Pd ← S∗;
5 Pt ← r oulette();
6 while Pt ∈ Mar k do
7 Pt ← r oulette() ;
8 break; // mode 1
9 case 1
10 11 12 13 S ← argmax
Pd ∈P
Pt ← argmax
Pd ∈P\S
Pd ← S∗;
break; // mode 2
14 15 case 2
16 17 Pd ← argmax
Pd. f i t;
Pd ∈P
Pt ← argmin
Pd. f i t;
Pd ∈P
break; // mode 3
18 mode ← (mode + 1) mod 3;
19 S ← Pt ,U ← S \ Pd ,U ′ ← Pd \ S;
20 l ← di st(S, Pd );
21 while di st(S, Pd ) > α ∗ l do
22 u ← argmax
u;
u∈U
23 24 S ← S \ {u},U ← U \ {u};
u′ ← argmax
u′ ∈ U ′;
u′∈U ′
25 S ← S ∪ {u′},U ′ ← U ′ \ {u′};
26 if α ∗ l < di st(S, Pd ) < (1− α) ∗ l ∧ f (S) > f (Pt ) then
27 Pt ← S;
28 return mode, P ;
The proposed strategy, known as the multiple path-relinking approach outlined in
Algorithm 5, enhances the population’s search capability by guiding it towards better
neighborhoods and ensuring diversity among individuals. In the current stage mode,
considering the current best solution S∗, the local best solutions of each individual
P = {P0, P1,..., P|P|}, and the marker set Mar k, we designate the index Pt to identify
123
17 Page 14 of 32 Y. Zhang et al.
the individual in the population to be modified, and Pd to represent the guiding solution.
To determine which solution to modify and the guidance solution, we alternate between
different stages (lines 2–18). If mode= 0, we employ a roulette function to randomly
select an unmarked individual to be moved towards the optimal solution S∗ (lines
3–8). If mode= 1, during the search, we identify the indices of the two individuals
with the best performance in P and move the second-best individual towards the
optimal solution S∗ (lines 9–13). If mode= 2, we locate the index Pd of the worst
performing individual in the current cycle and the index Pt of the best performing
individual (lines 14–17). Subsequently, the alternating selection of mode is auto-
increasing within module 3 (line 18). Once the solution Pt to be modified and the
guidance solution Pd are determined, we direct Pt to search in the direction of Pd
(line 19). The distance between two solutions, denoted as S and Pd , is computed by
quantifying the number of distinct sets they have in common. This count is then stored
in the variable l (line 20). During this process, the unique information of the guiding
solution gradually assimilates into and is utilized by the current solution, resulting in
multiple intermediate solutions. We eliminate inefficient information by removing the
set with the highest f value in Pt \Pd from Pt , and integrate the set with the highest
f value in Pd \Pt to approach the guidance solution. If the calculated distance falls
within the range of α ×l to (1− α) ×l, where α is a parameter satisfying 0 < α < 1,
the solution S will be selected and added to the collection of solutions Pt (lines 26–27).
This procedure is repeated until the generated intermediate solution and the guidance
solution exhibit minimal differences (lines 21–27). Finally, we return mode and the
newly generated population P (line 28).
3.5 The dynamic resource allocation strategy
The proposed dynamic resource allocation (DRA) strategy assesses the performance
of each individual within the population based on its search frequency for the optimal
solution during the last periodic search process. This performance metric drives the
allocation of computational resources through a round-robin approach. Additionally,
a subset of individuals with specific labels is excluded from resource allocation in the
current cycle, effectively reducing the number of individuals engaged in simultaneous
searching. However, to ensure fairness and prevent permanent exclusion, these labeled
individuals are re-evaluated and potentially re-labeled at the end of each cycle. This
strategy aims to optimize computational resource utilization and promote efficient
individual search behaviors.
Algorithm 6 presents a comprehensive depiction of the dynamic resource allocation
process, which determines the individual to suspend the search in subsequent iterations,
allowing computational resources to be focused on individuals with promising poten-
tial. It is worth noting that the dynamic resource allocation (DRA) is executed every L
iterations to provide an opportunity for underperforming individuals to enhance their
performance and develop into promising candidates. This strategy is well-suited for
facilitating early rapid convergence while also fostering diversity among individuals.
To elaborate further, the current set of markers, denoted as Mar k, is utilized to pre-
vent the re-marking of individuals that were not explored in the previous L rounds.
123
An effective population-based… Page 15 of 32 17
Algorithm 6: Dynamic resource allocation procedure–D R A
Input: markers of population Mar k, maximum ratio of the population Rmar k , hit count set of the
population H C.
Output: Mar k.
1 Mar k′ ← Mar k; Mar k ← ∅; k ← 0;
2 while k < Rmar k × |P| do
3 d ← argmin
H Cd ;
Pd ∈U \{Mar k′∪Mar k}
4 Mar k ← Mar k ∪ {Pd };
5 k ← k + 1;
6 return Mar k;
Additionally, the hit count set, denoted as H C, keeps track of the number of times
each individual has updated the global best solution. The first line of the DRA initial-
izes certain parameters. Subsequently, the algorithm searches for the individual that
has not discovered the global best solution within L iterations, as well as those that
have not been marked in the {Mar k′ ∪ Mar k} set (lines 2–5). Finally, the updated
Mar k is returned to the main procedure, ensuring that computational resources are
not allocated to individuals present in the Mar k set (line 6).
3.6 The fix-and-optimize procedure
The fix-and-optimize (FO) strategy is an efficient approach designed to tackle chal-
lenging optimization problems, especially those susceptible to getting trapped in local
optima Toledo et al. (2015); Dorneles et al. (2014); Joncour et al. (2023). It leverages
the combined power of fixing promising sets and employing a distinct search mode
to effectively navigate the search landscape. Specifically, in PSSC, we fix selected
sets in the current solution, then remove all unfixed sets and revert the solution to a
previous state. Subsequently, we employ the MTS to optimize this infeasible solution,
effectively restoring its feasibility. This creates a jump in the search space, allowing
exploration of alternative paths.
The pseudo code is reported in Algorithm 7. Firstly, the algorithm initializes two
counter variables k= 0,t = 0 (line 1) and marks all sets as unfixed (line 3). The loop
iterates until kmax consecutive iterations are completed without any improvement in the
solution (lines 2–17). Each loop involves a backtracking process where the algorithm
removes γ sets with minimum score values from the unfixed pool (S \ Fi x) (lines 4–
7). Notably, certain promising sets within the candidate solution are fixed and remain
untouched unless the best solution (S∗) undergoes an update. Following this removal,
the remaining sets in S are marked as fixed (line 8) and cannot be removed again until
they are explicitly unfixed. Afterwards, the algorithm attempts to repair the incomplete
solution using a greedy heuristic, which involves iteratively adding the set with the
highest scor e value until the solution becomes feasible (lines 9–11). Following that,
MTS is called again with the exclusion of any movement pertaining to the fixed sets
(line 12). This procedure is seen as a dynamic optimization process, wherein new
sets are incrementally added into the foundation of the previously established sets.
123
17 Page 16 of 32 Y. Zhang et al.
Algorithm 7: Fix-and-optimize procedure–F O
scor e(s);
};
Input: Candidate solution S, current best solution S∗, backtrack step γ, maximum allowed
iterations without improvement kmax.
Output: Generated solution S.
1 k ← 0;
2 while k < kmax do
3 t ← 0; Fi x= φ;
4 while t < γ do
5 s′ ← argmin
s∈S
′
6 S ← S \ {s
7 t ← t + 1;
8 Fi x ← S; // Fix the sets left in S;
9 while S is not feasible do
10 s′ ← argmax
scor e(s);
s∈M\S
11 S ← S ∪ {s′};
12 13 14 15 S ← M T S(S, M \ Fi x);
if f (S) < f (S∗) then
S∗ ← S;
k ← 0;
16 17 18 return S;
else
k ← k + 1;
If the newly generated solution is better than the best solution found, the algorithm
updates S∗ with S and resets the counter k (lines 13–15). Otherwise, the counter simply
increases by 1 (line 17). Finally, the algorithm returns the current solution S (line 18).

5 Conclusion and future work
In this paper, we have presented a highly efficient algorithm, known as PSSC, designed
specifically for addressing the PSCP. We have introduced a novel framework for local
improvement, aimed at iteratively identifying a thinning k for MSKCP capable of cov-
ering a minimum of n elements. Further, we have proposed intra-population strategies
to effectively handle exploitation, encompassing the modified tabu search and fix-and-
optimize techniques. In terms of exploration, we have introduced an inter-population
approach called the multiple path-relinking strategy. Furthermore, in order to enhance
computational efficiency, we have integrated a dynamic resource allocation strategy.
By combining these powerful strategies, PSSC has emerged as a successful solver for
PSCP.
The effectiveness and efficiency of PSSC have been extensively evaluated on a
diverse set of existing and newly generated instances. Our experimental findings
demonstrate that PSSC exhibits exceptional performance, surpassing the state-of-
the-art algorithms in terms of the quality of solutions obtained. Notably, PSSC has
improved upon 67 best-known solutions. It is worth highlighting that PSSC demon-
strates a notable advantage when applied to large-scale instances, making it well-suited
for real-world scenarios.
As for future work, it would be beneficial to reduce the number of parameters or
explore adaptive approaches for parameter value selection. Additionally, it would be
interesting to adapt some of the innovative ideas employed in PSSC to tackle other
challenging combinatorial optimization problems.